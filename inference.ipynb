{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "from model import Transformer\n",
    "import sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load config \n",
    "config = utils.get_config(\"config.yaml\")\n",
    "\n",
    "## Load Tokenizer\n",
    "src_tokenizer = utils.load_tokenizer(config, config['src_lang'])\n",
    "tgt_tokenizer = utils.load_tokenizer(config, config['tgt_lang'])\n",
    "\n",
    "## Update the vocan size in the config\n",
    "config['src_vocab_size'] = src_tokenizer.get_vocab_size()\n",
    "config['tgt_vocab_size'] = tgt_tokenizer.get_vocab_size()\n",
    "\n",
    "## Define Model\n",
    "model = Transformer(**config)\n",
    "## Load checkpoints\n",
    "state = torch.load(\"models/checkpoints/tuned_model_29.pt\")\n",
    "## Load model with weights\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Params\n",
    "src_seq_len = 200\n",
    "tgt_seq_len = 200\n",
    "\n",
    "sos_token_id = src_tokenizer.token_to_id('[SOS]')\n",
    "eos_token_id = src_tokenizer.token_to_id('[EOS]')\n",
    "pad_token_id = src_tokenizer.token_to_id('[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, sampling_strategy = \"greedy\"):\n",
    "\n",
    "    src_tokens = src_tokenizer.encode(sentence).ids\n",
    "    num_of_src_pad_tokens = src_seq_len - len(src_tokens) - 2\n",
    "\n",
    "    encoder_input = torch.cat([\n",
    "            torch.tensor([sos_token_id], dtype = torch.long),\n",
    "            torch.tensor(src_tokens, dtype = torch.long),\n",
    "            torch.tensor([eos_token_id], dtype = torch.long),\n",
    "            torch.tensor([pad_token_id] * num_of_src_pad_tokens, dtype = torch.long)\n",
    "        ], dim = 0).to(device)\n",
    "\n",
    "    encoder_mask = (encoder_input != pad_token_id).int().to(device)\n",
    "\n",
    "    if sampling_strategy == \"greedy\":\n",
    "        decoder_output = sampling.greedy_decode(\n",
    "            model, \n",
    "            source= encoder_input,\n",
    "            source_mask= encoder_mask,\n",
    "            tokenizer_src= src_tokenizer,\n",
    "            tokenizer_tgt=tgt_tokenizer,\n",
    "            max_len= tgt_seq_len,\n",
    "            device = device\n",
    "        )\n",
    "    else:\n",
    "        decoder_output = sampling.beam_search_decode(\n",
    "            model, \n",
    "            beam_size = 2,\n",
    "            source= encoder_input,\n",
    "            source_mask= encoder_mask,\n",
    "            tokenizer_src= src_tokenizer,\n",
    "            tokenizer_tgt=tgt_tokenizer,\n",
    "            max_len= tgt_seq_len,\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "    output = tgt_tokenizer.decode(decoder_output.tolist())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'हम दोस्तों हैं'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"we are friends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'हम दोस्त हैं'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"we are friends\", sampling_strategy=\"beam\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
